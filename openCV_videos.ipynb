{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "openCV_videos.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMK1FirxiqkWxW0ry24qsn7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manohar2000/Technocollab_DataScience/blob/master/openCV_videos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhD2UmWrO4zT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEFMo_fjPTDU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "f42f1def-938e-45c7-c2ea-f0bcd7ba8c68"
      },
      "source": [
        "'''\n",
        "creating a object of VideoCapture ; \n",
        "cv2.Video(x) x is an argument to specify the camera\n",
        "normally one camera will be connected by simply passing 0 or -1\n",
        "second camera can be passed by passing 1 and so on\n",
        "'''\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "'''\n",
        "sometimes cap may not have been initialized the capture. \n",
        "cap.isOpened() can be used to check this. \n",
        "if cap.isOpened() returns False, we can open it with cap.open() \n",
        "'''\n",
        "\n",
        "print(cap.isOpened()) \n",
        "cap.open(0)\n",
        "print(cap.isOpened())   \n",
        "\n",
        "while(True):\n",
        "  '''\n",
        "  #cap.read() return a bool, If a frame is read it will return true\n",
        "  # some features can be accessed by the cap.get(propid) method\n",
        "  # e.g: we can check the frame width and height by cap.get(3) and cap.get(4).\n",
        "  # It gives 640x480 by default. But If we want to modify it to 320x240.\n",
        "  # Just use ret = cap.set(3,320) and ret = cap.set(4,240).\n",
        "\n",
        "  '''  \n",
        "  ret, frame = cap.read() \n",
        "\n",
        "  '''\n",
        "  cv2.color is used to convert an image from one color space to another\n",
        "  There are more than 150 color-space coversion methods available.\n",
        "  for eg.\n",
        "  1) grayscale : cv2.cvtColor(src, cv2.COLOR_BGR2GRAY ) \n",
        "  2) HSV(mostly used in object tracking) : cv2.cvtColor(src, cv2.COLOR_BGR2HSV )\n",
        "  Here src refers to the input frame which can be either a live webcam or a video\n",
        "  '''\n",
        "  # Our operations on the frame come here\n",
        "  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
        "\n",
        "  '''\n",
        "  cv2.imshow() is used to show a image in the window\n",
        "  cv2. waitKey() is a keyboard binding function. \n",
        "  Its argument is the time in milliseconds.\n",
        "  The function waits for specified milliseconds for any keyboard event.\n",
        "  0xFF is a hexadecimal constant which is 11111111 in binary. \n",
        "  By using bitwise AND (&) with this constant,\n",
        "  it leaves only the last 8 bits of the original (in this case, whatever cv2.waitKey(0) is).\n",
        "\n",
        "  '''\n",
        "\n",
        "  # Display the resulting frame\n",
        "  cv2.imshow('frame',gray)\n",
        "  if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# When everything done, release the capture\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-2e48f4044706>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m# Our operations on the frame come here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;31m# Display the resulting frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lffRxrhjcxzn",
        "colab_type": "text"
      },
      "source": [
        "Note : The above code won't work on collab, since collab requires some special access to your hardware. For taking input from your webcam we'll have run the below snippets.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRPlQC2_dEiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFM2EFN_dEhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}